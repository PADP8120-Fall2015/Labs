
---
title: "PADP_8120_Lab4: Random Variables and Distributions"
author: "Tyler Scott"
date: "2015-08-03 ![Creative Commons License](images/cc-by.png)" 
output:
  html_document:
    highlight: pygments
    theme: cerulean
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
---

## Lab Topics

### Subject Area

- Distributions in R
- Sampling

### R Methods

- Simulation
- Sampling
- Piping
- Loops

##Goals:

After this lab you will be able to:

- simulate distributions of random variables in R
- perform sampling in R
- use piping to integrate several functions into one call
- write a basic loop

## 

This lab is adapted from materials by:

- Andrew Bray and Mine Cetinkaya-Rundel 
- Christopher Gandrud


# Basic loops

### Using a for loop
In many coding situations you will want to create an iterative loop so that your computer can cycle through a task automatically rather than you having to write it all out by hand. The most basic way to do this is using a for loop in R â€” there are some other ways we can do this using while and repeat which we shall cover in
the next class.

##### Example: A basic loop to sum integers

```{r eval=FALSE}
x <- 0 # Counter initialised to zero
a <- 1:10
for(i in a) {
print(i)
x <- x + i
}
x
```

#### Syntax

for(variable in sequence) statement
 - There will be one iteration of the statement for each component of the vector sequence, with variable taking on the values of those components. 
 
 - The statement can itself be compound i.e. include several commands in
which case you need to enclose it in brackets `for(variable in sequence) {statement}`

#### Shortening 

In the above example we created the sequence first i.e. `a <- 1:n` and then set `i` to cycle through it in the `for()` statement. To be more concise, you can just enter the sequence you want to use directly in the loop itself:

```{r eval=FALSE}
for(i in 1:10) {
print(i)
}
```

1. Write a simple loop that draws 10 different values from the `t` distribution (hint: `rt()`)

```{r}
fill.vector = NA #make object to store the random values I draw
df.value = 30 #t-distribution requires a df value, since width of distribution (how heavy tails are) is determined by df

# loop through values 1:10, draw 1 random value from t-dist with df = 30, assign to ith spot in the fill.vector object
for (i in 1:10)
{
  fill.vector[i] = rt(1,df=df.value)
}
print(fill.vector)
```


## if and if else statements

Often when in the loop of a function you will want to do different things depending upon the iteration you are on. You can do this using the `if` statement

### If Else statements

```{r eval=FALSE}
x <- c(-3, 5, 12)
y <- rep(NA, length(x))
for(i in 1:length(x)) {
if(x[i] >= 0) {
y[i] <- x[i]
} else {
y[i] <- -x[i]
}
}
y
```

#### Syntax

- if (condition) true.branch else false.branch
- The else part is optional and the true.branch or false.branch can be compound statements enclosed in { }.

## Loop caveats

- Avoid vector conditions

- You need to be careful when you are evaluating conditions in R, particularly within an `if` statement. 

- When writing a loop, make sure that:
    - the condition you are evaluating is only of length 1
    - when you have any condition it takes a single TRUE or FALSE value.
  
For example try running
```{r eval=FALSE}
x <- c(1,-2,3)
if(x < 0) print("Hi!")
```

2. Why doesn't this work?

This does not work because `x` is an object that contains three numbers (1, -2, and 3). Thus, when we ask R to evaluate the question, "Is X < 0?", R doesn't know what to do since there isn't just one answer. 

```{r eval=FALSE}
x <- c(-1, 2, -3)
if(x < 0) print("Hi!")
```

3. What about this error? What R does in this situation is use only the first condition value and a warning is issued.

This is actually the same error; the difference is, in the prior example, when R tries to evaluate "Is x < 0?", the first number it queries produces a FALSE response (since 1 is not less than 0). Since the response is FALSE, R does not print "hi". Then, R realizes that x contains two more values, and gives an error. In the latter example, the answer to the first value (i.e., x[1]) is TRUE, so R prints "hi", and then chokes when it realizes that there are two more values associated with x. 

4. Write an `if` `else` loop that takes 10 random samples from the standard normal distribution (hint: `rnorm()`), and print the character string "positive" if the sampled value is greater than 0 and "negative" if the sampled value is less than 0.

```{r}
for (i in 1:10)
{
  if (rnorm(1)>0) {print('positive')}
  else {print('negative')}
}
```

Note that we could also do this another way, by having R generate 10 random samples and then using the `ifelse` function as a shortcut. The `ifelse` function takes three inputs: (1) the object to iterate over; (2) what do if the condition is TRUE for a given iteraction; and (3) what to do if the condition is FALSE for a given iteration. Note that here we won't need to specify the `print` function, because `ifelse` returns the specified value based upon the TRUE/FALSE evaluation. 

```{r}
ifelse(rnorm(10)>0,'positive','negative')
```

### Breaking a loop 

Sometimes you might want to end a loop early if a certain condition has been met. In this case we use the break command. This will cause the computer to jump out of the loop when the break is encountered.

```{r eval=FALSE}
# The break command
for(i in 1:10) {
print(i)
if(i == 7) break
}
i
```

5. Write a loop that draws ten values from a uniform distribution between 0 and 10, and "breaks" when a value is drawn that is greater than 8. 

```{r eval=FALSE}
for(i in 1:10) {
  print(i)
  if(runif(n=1,min=0,max=10)>8) break
}
```

### "Nexting" a loop 

Alternatively we may wish to sometimes just skip to the next iteration of the loop in which case we would want to use the next command:

```{r eval=FALSE}
for(i in 1:10) {
if(i == 7) next # Skip all lines below this and start next loop iteration
print(i)
}
```

6. Write a loop that uses a `next` command to skip something (of your choice).

```{r}
color.list <- c('red','blue','green','yellow')
for (i in color.list)
{
  if (i == 'green') next
  print(i)
}
```


# Normal Distribution

Now, let's move on to a different subject, the normal distribution. We'll be working with measurements of body dimensions.  This data set 
contains measurements from 247 men and 260 women, most of whom were considered 
healthy young adults.

```{r load-data, eval=TRUE,echo=FALSE}
load("input/bdims.RData")
```

Let's take a quick peek at the first few rows of the data.

```{r head-data, eval=FALSE}
head(bdims)
```

You'll see that for every observation we have 25 measurements, many of which are
either diameters or girths.  A key to the variable names can be found at 
[http://www.openintro.org/stat/data/bdims.php](http://www.openintro.org/stat/data/bdims.php),
but we'll be focusing on just three columns to get started: weight in kg (`wgt`), 
height in cm (`hgt`), and `sex` (`1` indicates male, `0` indicates female).

Since males and females tend to have different body dimensions, it will be 
useful to create two additional data sets: one with only men and another with 
only women.

```{r male-female, eval=TRUE,echo=FALSE}
mdims <- subset(bdims, sex == 1)
fdims <- subset(bdims, sex == 0)
```

7.  Make a histogram (`hist()`) of men's heights and a histogram of women's heights.  How would you compare the various aspects of the two distributions?

```{r}
hist(mdims$hgt)
```

```{r}
hist(fdims$hgt)
```

Note that ggplot has a quick way to perform the above operations without prior subsetting:
```{r message=FALSE,warning=FALSE}
library(ggplot2)
ggplot(bdims, aes(x=hgt)) + geom_histogram(binwidth=5)+ facet_wrap(~sex)
```

In any case, both distributions are approximately a normal distribution. As we might epect, the average male height is a bit taller.

## The normal distribution

We can plot a normal distribution curve on top of a histogram to see how closely the data follow a normal distribution. This normal curve should have the same mean and standard deviation as the data. We'll be working with women's heights, so let's store them as a separate object and then calculate some statistics that will be referenced later. 

```{r female-hgt-mean-sd, eval=TRUE,echo=FALSE}
fhgtmean <- mean(fdims$hgt)
fhgtsd   <- sd(fdims$hgt)
```

Next we make a density histogram to use as the backdrop and use the `lines` 
function to overlay a normal probability curve. The difference between a 
frequency histogram and a density histogram is that while in a frequency 
histogram the *heights* of the bars add up to the total number of observations, 
in a density histogram the *areas* of the bars add up to 1. The area of each bar 
can be calculated as simply the height *times* the width of the bar. Using a 
density histogram allows us to properly overlay a normal distribution curve over 
the histogram since the curve is a normal probability density function.
Frequency and density histograms both display the same exact shape; they only 
differ in their y-axis. You can verify this by comparing the frequency histogram 
you constructed earlier and the density histogram created by the commands below.

```{r hist-height, eval=FALSE}
hist(fdims$hgt, probability = TRUE)
x <- 140:190
y <- dnorm(x = x, mean = fhgtmean, sd = fhgtsd)
lines(x = x, y = y, col = "blue")
```

After plotting the density histogram with the first command, we create the x- 
and y-coordinates for the normal curve.  We chose the `x` range as 140 to 190 in 
order to span the entire range of `fheight`.  To create `y`, we use `dnorm` to 
calculate the density of each of those x-values in a distribution that is normal
with mean `fhgtmean` and standard deviation `fhgtsd`.  The final command draws a
curve on the existing plot (the density histogram) by connecting each of the 
points specified by `x` and `y`. The argument `col` simply sets the color for 
the line to be drawn. If we left it out, the line would be drawn in black.

The top of the curve is cut off because the limits of the x- and y-axes are set 
to best fit the histogram.  To adjust the y-axis you can add a third argument to
the histogram function: `ylim = c(0, 0.06)`.

8.  Based on the this plot, does it appear that the data follow a nearly normal 
    distribution?

Yes, as we thought before, when we print a normal curve on top of the histogram, it's clear that the height distribution is nearly normal. 

## Evaluating the normal distribution

Eyeballing the shape of the histogram is one way to determine if the data appear
to be nearly normally distributed, but it can be frustrating to decide just how 
close the histogram is to the curve. An alternative approach involves 
constructing a normal probability plot, also called a normal Q-Q plot for 
"quantile-quantile".

```{r eval=FALSE}
qqnorm(fdims$hgt)
qqline(fdims$hgt)
```

A data set that is nearly normal will result in a probability plot where the 
points closely follow the line.  Any deviations from normality leads to 
deviations of these points from the line.  The plot for female heights shows 
points that tend to follow the line but with some errant points towards the 
tails.  We're left with the same problem that we encountered with the histogram 
above: how close is close enough?

A useful way to address this question is to rephrase it as: what do probability 
plots look like for data that I *know* came from a normal distribution?  We can 
answer this by simulating data from a normal distribution using `rnorm`.

```{r sim-norm, eval=FALSE}
sim_norm <- rnorm(n = length(fdims$hgt), mean = fhgtmean, sd = fhgtsd)
```

The first argument indicates how many numbers you'd like to generate, which we 
specify to be the same number of heights in the `fdims` data set using the 
`length` function.  The last two arguments determine the mean and standard 
deviation of the normal distribution from which the simulated sample will be 
generated.  We can take a look at the shape of our simulated data set, `sim_norm`, 
as well as its normal probability plot.

9.  Make a normal probability plot of `sim_norm`.  Do all of the points fall on 
    the line?  How does this plot compare to the probability plot for the real 
    data?

```{r qq, eval=FALSE}
qqnorm(sim_norm)
qqline(sim_norm)
```

As we might expect, the simulated data fit the qqline a little more perfectly, which makes sense since these values were drawn from a normal distribution. 


Even better than comparing the original plot to a single plot generated from a normal distribution is to compare it to many more plots using the following 
function. It may be helpful to click the zoom button in the plot window.

```{r qqnormsim, eval=FALSE}
qqnormsim(fdims$hgt)
```

10.  Does the normal probability plot for `fdims$hgt` look similar to the plots created for the simulated data?  That is, do plots provide evidence that the female heights are nearly normal?

Actually, yeah it does. In fact, it's basically impossible to tell the difference between the qq plot of the female height data and the plots for simulated data. This is pretty convincing evidence of normality, because it indicates that even a perfectly normal distribution will have about as much sampling variability as we see in the actual data. 


11.  Using the same technique, determine whether or not female weights appear to 
    come from a normal distribution.


# Sampling Distributions

Next, let's investigate the ways in which the statistics from a random 
sample of data can serve as point estimates for population parameters.  We're 
interested in formulating a *sampling distribution* of our estimate in order 
to learn about the properties of the estimate, such as its distribution.

## The data

We consider real estate data from the city of Ames, Iowa.  The details of 
every real estate transaction in Ames is recorded by the City Assessor's 
office.  Our particular focus for this lab will be all residential home sales 
in Ames between 2006 and 2010.  This collection represents our population of 
interest.  In this lab we would like to learn about these home sales by taking 
smaller samples from the full population.  Let's load the data.

```{r eval=FALSE}
download.file("http://www.openintro.org/stat/data/ames.RData", destfile = "ames.RData")
load("ames.RData")
```

```{r eval=TRUE,message=FALSE,results='hide'}
load('input/ames.RData')
```

We see that there are quite a few variables in the data set, enough to do a 
very in-depth analysis.  For this lab, we'll restrict our attention to just 
two of the variables: the above ground living area of the house in square feet 
(`Gr.Liv.Area`) and the sale price (`SalePrice`).  To save some effort 
throughout the lab, create two variables with short names that represent these 
two variables.  

```{r assign, eval=TRUE}
area <- ames$Gr.Liv.Area
price <- ames$SalePrice
```

Let's look at the distribution of area in our population of home sales by 
calculating a few summary statistics and making a histogram.

```{r area, eval=FALSE}
summary(area)
hist(area)
```

12.  Describe this population distribution.

```{r eval=TRUE}
summary(area)
hist(area)
```

These data look fairly normal as well. However, there appears to be a slight rightward skew - this makes sense, since houses cannot have LESS than 0 square feet, but someone can certainly have a huge mansion that has far more square feet than average. 

## The unknown sampling distribution

In this lab we have access to the entire population, but this is rarely the 
case in real life.  Gathering information on an entire population is often 
extremely costly or impossible.  Because of this, we often take a sample of 
the population and use that to understand the properties of the population.

If we were interested in estimating the mean living area in Ames based on a 
sample, we can use the following command to survey the population.

```{r samp1, eval=TRUE}
samp1 <- sample(area, 50)
```

This command collects a simple random sample of size 50 from the vector 
`area`, which is assigned to `samp1`.  This is like going into the City 
Assessor's database and pulling up the files on 50 random home sales.  Working 
with these 50 files would be considerably simpler than working with all 2930 
home sales.

13.  Describe the distribution of this sample. How does it compare to the 
    distribution of the population?
   
If we're interested in estimating the average living area in homes in Ames 
using the sample, our best single guess is the sample mean.

```{r mean-samp1, eval=TRUE}
mean(samp1)
```

Depending on which 50 homes you selected, your estimate could be a bit above 
or a bit below the true population mean of 1499.69 square feet.  In general, 
though, the sample mean turns out to be a pretty good estimate of the average 
living area, and we were able to get it by sampling less than 3\% of the 
population.

14.  Take a second sample, also of size 50, and call it `samp2`.  How does the 
    mean of `samp2` compare with the mean of `samp1`?  Suppose we took two 
    more samples, one of size 100 and one of size 1000. Which would you think 
    would provide a more accurate estimate of the population mean?

```{r}
samp2 <- sample(area, 50)
mean(samp1)
mean(samp2)
```

Of course, the two sample means are different. The typical difference should decrease as we go to 100 and then 1000 (but might not in very case, since the results are still subject to random variation).

```{r}
n = 100
samp1 <- sample(area, n)
samp2 <- sample(area, n)
mean(samp1)
mean(samp2)
```

```{r}
n = 1000
samp1 <- sample(area, n)
samp2 <- sample(area, n)
mean(samp1)
mean(samp2)
```

Not surprisingly, every time we take another random sample, we get a different 
sample mean.  It's useful to get a sense of just how much variability we 
should expect when estimating the population mean this way. The distribution 
of sample means, called the *sampling distribution*, can help us understand 
this variability. In this lab, because we have access to the population, we 
can build up the sampling distribution for the sample mean by repeating the 
above steps many times. Here we will generate 5000 samples and compute the 
sample mean of each.

```{r loop, eval=TRUE}
sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   }

hist(sample_means50)
```

If you would like to adjust the bin width of your histogram to show a little 
more detail, you can do so by changing the `breaks` argument.

```{r hist-breaks, eval=TRUE}
hist(sample_means50, breaks = 25)
```

Here we use R to take 5000 samples of size 50 from the population, calculate 
the mean of each sample, and store each result in a vector called 
`sample_means50`.

15.  How many elements are there in `sample_means50`?  Describe the sampling 
    distribution, and be sure to specifically note its center.  Would you 
    expect the distribution to change if we instead collected 50,000 sample 
    means?

```{r}
str(sample_means50)
```

There are 5000 values. The distribution (below) looks basically normal. Most importantly, it appears to be basically centered around the population mean (pop. mean = `r mean(area)`, shown with a red dashed line below: 

```{r}
hist(sample_means50)
abline(v = mean(area),col='red',lwd=3,lty=2)
```

In reality, the distribution probably wouldn't change too much if we collected 50,000 instead of 5,000 sample means, because 5,000 is a lot and because sample means vary less than individual observations (that is, n = 5000 vs. n = 50,000 might produce very different distributions, but when you take 5000 samples of 50, you end up with a pretty large sample size anyways).

## Back to the `for` loop

Let's review the `for` loop in the context of this example. Again, the idea behind the for loop is *iteration*: it allows you to execute code as many times as you want without having to type out every 
iteration.  

```{r loop-again, eval=FALSE}
sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   }
```

Let's consider this code line by line to figure out what it does.  In the 
first line we *initialized a vector*.  In this case, we created a vector of 
5000 zeros called `sample_means50`.  This vector will will store values 
generated within the `for` loop.

The second line calls the `for` loop itself.  The syntax can be loosely read as, 
"for every element `i` from 1 to 5000, run the following lines of code". You 
can think of `i` as the counter that keeps track of which loop you're on. 
Therefore, more precisely, the loop will run once when `i = 1`, then once when 
`i = 2`, and so on up to `i = 5000`.

The body of the `for` loop is the part inside the curly braces, and this set of 
code is run for each value of `i`.  Here, on every loop, we take a random 
sample of size 50 from `area`, take its mean, and store it as the 
$i$<sup>th</sup> element of `sample_means50`.

The `for` loop allows us to not just run the code 5000 times, but to neatly 
package the results, element by element, into the empty vector that we 
initialized at the outset. 

16.  To make sure you understand what you've done in this loop, try running a smaller version.  Initialize a vector of 100 zeros called `sample_means_small`.  Run a loop that takes a sample of size 50 from `area` and stores the sample mean in `sample_means_small`, but only iterate from 1 to 100.  Print the output to your screen (type `sample_means_small` into the console and press enter).  How many elements are there in this object called `sample_means_small`? What does each element represent?

```{r}
sample_means_small = rep(0,100)

for (i in 1:length(sample_means_small))
{
  sample_means_small[i] <- mean(sample(area,50))
}
sample_means_small
```

There are 100 elements, each of which represents the mean of a sample of 50 houses in Ames. 

## Sample size and the sampling distribution

Mechanics aside, let's return to the reason we used a `for` loop: to compute a 
sampling distribution, specifically, this one.

```{r hist, eval=FALSE}
hist(sample_means50)
```

The sampling distribution that we computed tells us much about estimating 
the average living area in homes in Ames.  Because the sample mean is an 
unbiased estimator, the sampling distribution is centered at the true average 
living area of the the population, and the spread of the distribution 
indicates how much variability is induced by sampling only 50 home sales.

To get a sense of the effect that sample size has on our distribution, let's 
build up two more sampling distributions: one based on a sample size of 10 and 
another based on a sample size of 100.

```{r samp-10-100, eval=FALSE}
sample_means10 <- rep(NA, 5000)
sample_means100 <- rep(NA, 5000)

for(i in 1:5000){
  samp <- sample(area, 10)
  sample_means10[i] <- mean(samp)
  samp <- sample(area, 100)
  sample_means100[i] <- mean(samp)
}
```

Here we're able to use a single `for` loop to build two distributions by adding 
additional lines inside the curly braces.  Don't worry about the fact that 
`samp` is used for the name of two different objects.  In the second command 
of the `for` loop, the mean of `samp` is saved to the relevant place in the 
vector `sample_means10`.  With the mean saved, we're now free to overwrite the 
object `samp` with a new sample, this time of size 100.  In general, anytime 
you create an object using a name that is already in use, the old object will 
get replaced with the new one.

To see the effect that different sample sizes have on the sampling 
distribution, plot the three distributions on top of one another.

```{r plot-samps, eval=FALSE, tidy = FALSE}
par(mfrow = c(3, 1))

xlimits <- range(sample_means10)

hist(sample_means10, breaks = 20, xlim = xlimits)
hist(sample_means50, breaks = 20, xlim = xlimits)
hist(sample_means100, breaks = 20, xlim = xlimits)
```

The first command specifies that you'd like to divide the plotting area into 3 
rows and 1 column of plots (to return to the default setting of plotting one 
at a time, use `par(mfrow = c(1, 1))`). The `breaks` argument specifies the 
number of bins used in constructing the histogram.  The `xlim` argument 
specifies the range of the x-axis of the histogram, and by setting it equal 
to `xlimits` for each histogram, we ensure that all three histograms will be 
plotted with the same limits on the x-axis.

17.  When the sample size is larger, what happens to the center?  What about the spread?

Generally speaking, a larger sample size decreases the spread and increase the height at the center. 

18. Take a random sample of size 50 from `price`. Using this sample, what is your best point estimate of the population mean?

```{r}
price.sample.mean <- mean(sample(price,50))
price.sample.mean
```

Given this sample, the best guess for the mean is `r price.sample.mean`. 

19. Since you have access to the population, simulate the sampling distribution for $\bar{x}_{price}$ by taking 5000 samples from the population of size 50 and computing 5000 sample means.  Store these means in a vector called `sample_means50`. Plot the data, then describe the shape of this sampling distribution. Based on this sampling distribution, what would you guess the mean home price of the population to be? Finally, calculate and report the population mean.

```{r}
sample_means50 <- rep(sample(price,50),5000)
hist(sample_means50)
```

The sample distribution is (as expected) approximately normal. I'd guess that the mean home price is right about in the center of the distribution.

```{r}
mean(price)
```

The mean price is `r mean(price)`, which is pretty much in the center of the sample mean distribution. 

20. Change your sample size from 50 to 150, then compute the sampling distribution using the same method as above, and store these means in a new vector called `sample_means150`. Describe the shape of this sampling distribution, and compare it to the sampling distribution for a sample size of 50.  Based on this sampling distribution, what would you guess to be the mean sale price of homes in Ames?

```{r}
sample_means150 <- rep(sample(price,150),5000)
hist(sample_means150)
```

The "best guess" is about the same, but the new sampling distribution is a little bit tighter. In particular, there seems to be fewer outliers. 

21. Of the sampling distributions from 19 and 20, which has a smaller spread?  If we're concerned with making estimates that are more often close to the true value, would we prefer a distribution with a large or small spread?

# Piping

What all the cool kids are doing...

### What is piping? 

You learned a bit about piping in Lab 2, when we worked with functions in the `dplyr` packages. More generally, piping refers to proccess that pass a value forward to a function call.

### Why use piping?

Faster compilation.

Enhanced code readability.

### Piping basics

In R use `%>%` from the magrittr package.

```{r eval=FALSE}
install.packages('magrittr'); library(magrittr)
```

The `%>%` "special function" passes a value to the first argument of the next function call.

### Not piped

```{r eval=FALSE}
values <- rnorm(1000, mean = 10)
value_mean <- mean(values)
round(value_mean, digits = 2)
```

### Piped

```{r eval=FALSE}
rnorm(1000, mean = 10) %>% mean() %>% round(digits = 2)
```

22. Read in the body dimensions data file again, subset out only the female heights, find the standard deviation, and round to the nearest 3 digit decimal using the `%>%` operator to combine both all into a single line. 

```{r message = FALSE,warning=FALSE}
load('input/bdims.RData')
library(magrittr); library(dplyr)
bdims %>% filter(sex==1) %>% summarise(round(sd(hgt),3))
```

23. Why does the line of code below produce an NA result message rather than give you the standard deviation of your sample?

```{r eval=FALSE}
rnorm(1000, mean = 10) %>% mean() %>% sd() #DOESN'T WORK
```

This doesn't work because calling `mean` produces one number (the mean of the `rnorm` sample), which obviously can't take the standard deviation of (since you can't calculate the standard deviation of one number). 
